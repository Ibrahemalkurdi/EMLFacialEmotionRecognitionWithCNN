{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install livelossplot","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Activation, Dropout, LeakyReLU\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import SVG, Image\nfrom livelossplot import PlotLossesKerasTF\nprint(\"Tensorflow version:\", tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_dir=\"/kaggle/input/courserafacemoreco/train/\"\nvalidation_data_dir=\"/kaggle/input/courserafacemoreco/test/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = 0\nfor expression in os.listdir(train_data_dir):\n    print(str(len(os.listdir(train_data_dir+expression)))+\" \"+expression +\" images\")\n    num_classes += 1\nprint(num_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_rows, img_cols = 224, 224\n# img_size = 48 # old\nimg_size = 224 \nbatch_size = 64 # or 32\n\n\n\n# datagen_train = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True) # old\ndatagen_train = ImageDataGenerator(rescale=1. / 255,\n                                   rotation_range=30,\n                                   width_shift_range=0.3,\n                                   shear_range=0.3,\n                                   zoom_range=0.3,\n                                   height_shift_range=0.3,\n                                   horizontal_flip=True,\n                                   fill_mode='nearest')\n\ntrain_generator = datagen_train.flow_from_directory(train_data_dir,\n                                                    target_size=(img_rows,img_cols),\n                                                    batch_size=batch_size,\n                                                    class_mode='categorical',\n                                                    shuffle=True)\n\n# datagen_validation = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True) # old\ndatagen_validation = ImageDataGenerator(rescale=1. / 255,horizontal_flip=True)\n\nvalidation_generator = datagen_validation.flow_from_directory(validation_data_dir,\n                                                              target_size=(img_rows,img_cols),\n                                                              batch_size=batch_size,\n                                                              class_mode='categorical',\n                                                              shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_generator.n)\nprint(validation_generator.n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_SHAPE = (img_rows, img_cols, 3)\n\n# Create the base model from the pre-trained model MobileNet V2\nbase_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.trainable = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's take a look to see how many layers are in the base model\nprint(\"Number of layers in the base model: \", len(base_model.layers))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fine-tune from this layer onwards\nfine_tune_at = 100\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable =  False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_model = base_model.output\nglobal_average_layer = tf.keras.layers.GlobalAveragePooling2D()\ntop_model = global_average_layer(top_model)\nprint(top_model.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_model = Dense(1024)(top_model)\ntop_model = BatchNormalization()(top_model)\ntop_model = LeakyReLU()(top_model)\ntop_model = Dropout(0.25)(top_model)\n\ntop_model = Dense(1024)(top_model)\ntop_model = BatchNormalization()(top_model)\ntop_model = LeakyReLU()(top_model)\ntop_model = Dropout(0.25)(top_model)\n\ntop_model = Dense(512)(top_model)\ntop_model = BatchNormalization()(top_model)\ntop_model = LeakyReLU()(top_model)\ntop_model = Dropout(0.25)(top_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_model = tf.keras.layers.Dense(num_classes, activation='softmax')(top_model)\n\n#model = tf.keras.Sequential([base_model,global_average_layer,top_model])\nmodel = tf.keras.models.Model(inputs=base_model.input, outputs=top_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(lr=0.0005)\nloss_categ = tf.keras.losses.CategoricalCrossentropy()\nmodel.compile(optimizer=opt, loss=loss_categ, metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 200\n\nsteps_per_epoch = train_generator.n//train_generator.batch_size\nvalidation_steps = validation_generator.n//validation_generator.batch_size\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.1,\n                              patience=5,\n                              min_lr=0.00001,\n                              verbose=1, #me\n                              mode='auto')\n\n\ncheckpoint = ModelCheckpoint(\"CNNMoblieNetV2EmoDetFineTuneAndExtraLayers_weights.h5\",\n                             monitor='val_loss',\n                             save_best_only=True,#me\n                             save_weights_only=True,\n                             mode='min',\n                             verbose=1)\n\nearlystop = EarlyStopping(monitor='val_loss',\n                          min_delta=0,\n                          patience=14,\n                          verbose=1,\n                          restore_best_weights=True)\n\n\ncallbacks = [PlotLossesKerasTF(), checkpoint, reduce_lr, earlystop]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x=train_generator,\n                    steps_per_epoch=steps_per_epoch,\n                    epochs=epochs,\n                    validation_data=validation_generator,\n                    validation_steps=validation_steps,\n                    callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(model, to_file='CNNMoblieNetV2EmoDetFineTuneAndExtraLayers.png', show_shapes=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"CNNMoblieNetV2EmoDetFineTuneAndExtraLayers.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_json = model.to_json()\nwith open(\"JCNNMoblieNetV2EmoDetFineTuneAndExtraLayers.json\",\"w\") as json_file:\n    json_file.write(model_json)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}